{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "from keras.layers import Embedding, LSTM, Dense, Conv1D, MaxPooling1D, Dropout, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.text import Tokenizer,text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from IntegratedGradients import * \n",
    "from keras.models import load_model\n",
    "import pickle\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "# caleb_path = '/Users/CalebKaijiLu/Documents/yelp_dataset/'\n",
    "caleb_path = '/home/caleb/schoolwork/yelp_dataset/'\n",
    "selva_path = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only Run this on Server. If test trained models, use Gender_Prediction_Test.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(balanced_texts,balanced_labels,limit):\n",
    "    tokenizer = Tokenizer(num_words=20000)\n",
    "    tokenizer.fit_on_texts(balanced_texts)\n",
    "    sequences = tokenizer.texts_to_sequences(balanced_texts)\n",
    "    data = pad_sequences(sequences, maxlen=limit)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(20000, 128, input_length=limit))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv1D(64, 5, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=4))\n",
    "    model.add(LSTM(128,dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.summary()\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(data, np.array(balanced_labels), validation_split=0.5, epochs=3,batch_size = 64)\n",
    "    return tokenizer,model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:01:08.541012\n"
     ]
    }
   ],
   "source": [
    "t1 = datetime.now()\n",
    "with open(caleb_path + \"review.json\") as f:\n",
    "    reviews = f.read().strip().split(\"\\n\")\n",
    "# reviews = reviews[:10000]\n",
    "reviews = [json.loads(review) for review in reviews]\n",
    "print(datetime.now() - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "om5ZiponkpRqUNa3pVPiRg\n"
     ]
    }
   ],
   "source": [
    "with open(caleb_path + \"user_gender.json\") as f:\n",
    "    user_genders = f.read().strip().split(\"\\n\")\n",
    "user_gender = [json.loads(user_gender) for user_gender in user_genders]\n",
    "user_id_gender = {user['user_id']:user['gender'] for user in user_gender}\n",
    "print(user_gender[0]['user_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews_gender = [review for review in reviews if review['user_id'] in user_id_gender]\n",
    "genders = [user_id_gender[review_gender['user_id']] for review_gender in reviews_gender]\n",
    "bin_gender = [0 if gender =='male' else 1 for gender in genders]\n",
    "text_gender = [review_gender['text'] for review_gender in reviews_gender]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "user_dict = defaultdict(str);\n",
    "for review_gender in reviews_gender:\n",
    "    user_dict[review_gender['user_id']] += review_gender['text']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_gender_user = []\n",
    "bin_gender_user = []\n",
    "for user in user_dict:\n",
    "    if len(user_dict[user])>3000:\n",
    "        text_gender_user.append(user_dict[user])\n",
    "        bin_gender_user.append(0 if user_id_gender[user]=='male' else 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12509.800645213982\n",
      "122440 122440\n",
      "If you need an inexpensive place to stay for a night or two then you may consider this place but for a longer stay I'd recommend somewhere with better amenities. \n",
      "\n",
      "Pros:\n",
      "Great location- you're right by the train station, central location to get to old town and new town, and right by sight seeing his tours. Food, bars, and shopping all within walking distance. Location, location, location.\n",
      "Very clean and very good maid service\n",
      "\n",
      "Cons:\n",
      "Tiny rooms \n",
      "Uncomfortable bed \n",
      "Absolutely no amenities \n",
      "No phone in room \n",
      "No wardrobe \n",
      "\n",
      "Was given a lot of attitude about me and my husband sharing a room which was quite strange and we were charged 15 pounds more for double occupancy not sure why that matters I felt like it was a money grab. It was just handled in a kind of odd manner to me... \n",
      "\n",
      "If you book this hotel all you get is a bed, desk, and a bathroom. It isn't awful but know what you're getting into.Had an excellent lunch here. I shared the meat board and a large tomato salad with my husband which was just enough food for us both and very refreshing. Service was quick and attentive as well.They have an excellent breakfast here if you're a hungry traveler. Get one of the full breakfast plates. Service was really good.Delicious! I kept hearing to try a bagel while in Montreal and I'm glad I did! Wow, it was delightful. I had a regular bagel with cream cheese, it was plain cream cheese but there was something magical about it. Also, the chai tea was good. My fiancé had the breakfast bagel which was also tasty.I stopped in here and bought some books for the train for one pound each and a lovely scarf. My husband was lucky enough to score a designer jacket in his size. The store is very clean and organized although a bit tight.Nice little spot for a coffee. Not far from other stuff as well and close to the Hotel Motel One.This is a cute little restaurant, but it's in a spot where you wouldn't expect it to be. Very romantic and good service.  The waitress even asked if we had any dietary restrictions, allergies, or things we did not like. \n",
      "\n",
      "Me and my fiancé started off with the blue fin tuna appetizer with grapefruit and other delicious items. \n",
      "\n",
      "I had the scallops which were served with amazing slivers of pear and mushroom. They were buttery, rich and well cooked. \n",
      "\n",
      "My fiancé had the duck meat and heart plate. His was slightly tough but still very tasty. Very strange to say but wouldn't be shy of eating heart again. \n",
      "\n",
      "Dessert was a peach upside down cake with citrus sorbet. It was refreshing and a great way to end the meal.Our waitress was awesome! No idea what her name was but she had long hair and a lot of colorful tattoos. We had the happy hour special with their house red wine which was surprisingly really tasty. We snacked on a few things and all was good, it was the perfect pick me up before a late dinner.Amazing meal. Me and my fiancé came here for dinner and were seated in the garden/patio at a picnic table. We ended up talking to the couple next to us and sharing a few bites of items which was interesting. It's hard not to when sitting so close to someone. \n",
      "\n",
      "We started with the classic foie gras which was delicious, the homemade bread was the best ever.\n",
      "\n",
      "We had some of our neighbors brussel sprouts and lamb.\n",
      "\n",
      "Then came our beef for two, which was probably the best beef dish I've ever had. It was perfectly cooked and seasoned. \n",
      "\n",
      "Our waiter was great, I'm not sure of his name he was very nice and helpful since neither of us can read or speak French we were completely dependent on him. \n",
      "\n",
      "My complaint would be that the beef for two is WAY, WAY too much food for two people. We were obviously visitors to Montreal and I felt so bad about wasting the food. Please either do a smaller portion or warn patrons.. The beef is enough for four! \n",
      "\n",
      "Also if you are sitting on the patio/garden bring your shades!The drink was decent but watery and we had to wait twenty minutes in the heat for it. They seemed disorganized bubbling around in their little spaces, running back and forth putting out about a drink every couple minutes. With every other store on the street selling the same thing we could have waited somewhere indoors with a/c for a better drink. Just no.Very good food and service (while there). Started with the goat cheese and fig which was very good then both me and my husband had the lamb chop, and ended with the cheese plate with chutney. The only down side is when we made the reservation the lady said we only had 45 minutes to eat and they would kick us out even if we weren't done... We ended up getting to the restaurant early and it was dead (it picked up later) but we asked for any time so not sure why she needed to put us down for later and rush us... Did feel very rushed through dinner because of this so what could have been 5 stars is a 3.5 experience overall. \n",
      "\n",
      "You definitely need a reservation so be sure to make one. They turned quite a few people away. 1\n"
     ]
    }
   ],
   "source": [
    "text_lengths = [len(text) for text in text_gender_user]\n",
    "print(sum(text_lengths)/float(len(text_lengths)))\n",
    "print(len(text_gender_user),len(bin_gender_user))\n",
    "print(text_gender_user[0],bin_gender_user[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 10000, 1: 10000})"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_texts_gender = []\n",
    "balanced_gender = []\n",
    "limit = 10000  #Change this to grow/shrink the dataset\n",
    "neg_pos_counts = [0, 0]\n",
    "for i in range(len(text_gender)):\n",
    "    polarity = bin_gender[i]\n",
    "    if neg_pos_counts[polarity]<limit:\n",
    "        balanced_texts_gender.append(text_gender[i])\n",
    "        balanced_gender.append(bin_gender[i])\n",
    "        neg_pos_counts[polarity]+=1\n",
    "Counter(balanced_gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"tokenizer_gender_single_server.pickle\", \"rb\") as f:\n",
    "       tokenizer = pickle.load(f)\n",
    "\n",
    "model = load_model(\"yelp_gender_single_model_server.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 50000, 1: 50000})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_texts_gender_user = []\n",
    "balanced_gender_user = []\n",
    "limit = 40000  #Change this to grow/shrink the dataset\n",
    "neg_pos_counts = [0, 0]\n",
    "for i in range(len(text_gender_user)):\n",
    "    polarity = bin_gender[i]\n",
    "    if neg_pos_counts[polarity]<limit:\n",
    "        balanced_texts_gender_user.append(text_gender_user[i])\n",
    "        balanced_gender_user.append(bin_gender_user[i])\n",
    "        neg_pos_counts[polarity]+=1\n",
    "Counter(balanced_gender_user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the most probable sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(balanced_texts_gender)\n",
    "data = pad_sequences(sequences, maxlen=300)\n",
    "\n",
    "# get predictions for each of your new texts\n",
    "predictions = np.array(model.predict(data)).T[0]\n",
    "predictions_bi = np.array([1 if p<0.5 else 0 for p in predictions])\n",
    "truth = np.array(balanced_gender)\n",
    "\n",
    "print(np.sum(np.abs(predictions_bi-truth))/20000.0)\n",
    "\n",
    "\n",
    "idx_scores = np.argsort(predictions)[:100]\n",
    "for idx_score in idx_scores:\n",
    "    if 'wife' not in balanced_texts_gender[idx_score]: \n",
    "        print(balanced_texts_gender[idx_score],truth[idx_score],predictions[idx_score])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer_single, model_single = train_model(balanced_texts_gender,balanced_gender,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 3000, 128)         2560000   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 3000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 2996, 64)          41024     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 749, 64)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 2,699,969\n",
      "Trainable params: 2,699,969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 50000 samples\n",
      "Epoch 1/3\n",
      "50000/50000 [==============================] - 1616s - loss: 0.6025 - acc: 0.6747 - val_loss: 0.5746 - val_acc: 0.7302\n",
      "Epoch 2/3\n",
      "50000/50000 [==============================] - 1577s - loss: 0.4685 - acc: 0.7942 - val_loss: 0.4052 - val_acc: 0.8364\n",
      "Epoch 3/3\n",
      "50000/50000 [==============================] - 1605s - loss: 0.3563 - acc: 0.8598 - val_loss: 0.3747 - val_acc: 0.8453\n"
     ]
    }
   ],
   "source": [
    "tokenizer_user, model_user = train_model(balanced_texts_gender_user,balanced_gender_user,3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"tokenizer_gender_single_server.pickle\", \"wb\") as f:\n",
    "        pickle.dump(tokenizer_single, f)\n",
    "model_single.save(\"yelp_gender_single_model_server.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"tokenizer_gender_user_server.pickle\", \"wb\") as f:\n",
    "        pickle.dump(tokenizer_user, f)\n",
    "model_user.save(\"yelp_gender_user_model_server.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
